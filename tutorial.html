<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <title>Convolutional Neural Networks (LeNet) — DeepLearning 0.1 documentation</title>
    
    <link rel="stylesheet" href="tutorial_files/sphinxdoc.css" type="text/css">
    <link rel="stylesheet" href="tutorial_files/pygments.css" type="text/css">
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="tutorial_files/jquery.js"></script>
    <script type="text/javascript" src="tutorial_files/underscore.js"></script>
    <script type="text/javascript" src="tutorial_files/doctools.js"></script>
    <link rel="top" title="DeepLearning 0.1 documentation" href="http://deeplearning.net/tutorial/contents.html">
    <link rel="next" title="Denoising Autoencoders (dA)" href="http://deeplearning.net/tutorial/dA.html">
    <link rel="prev" title="Multilayer Perceptron" href="http://deeplearning.net/tutorial/mlp.html">
 
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-168290-9']);
  _gaq.push(['_trackPageview']);
</script>

  <script src="tutorial_files/ga.js" async="true"></script></head>
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="http://deeplearning.net/tutorial/genindex.html" title="General Index" accesskey="I">index</a></li>
        <li class="right">
          <a href="http://deeplearning.net/tutorial/dA.html" title="Denoising Autoencoders (dA)" accesskey="N">next</a> |</li>
        <li class="right">
          <a href="http://deeplearning.net/tutorial/mlp.html" title="Multilayer Perceptron" accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="http://deeplearning.net/tutorial/contents.html">DeepLearning 0.1 documentation</a> »</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="http://deeplearning.net/tutorial/contents.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Convolutional Neural Networks (LeNet)</a><ul>
<li><a class="reference internal" href="#motivation">Motivation</a></li>
<li><a class="reference internal" href="#sparse-connectivity">Sparse Connectivity</a></li>
<li><a class="reference internal" href="#shared-weights">Shared Weights</a></li>
<li><a class="reference internal" href="#details-and-notation">Details and Notation</a></li>
<li><a class="reference internal" href="#the-convolution-operator">The Convolution Operator</a></li>
<li><a class="reference internal" href="#maxpooling">MaxPooling</a></li>
<li><a class="reference internal" href="#the-full-model-lenet">The Full Model: LeNet</a></li>
<li><a class="reference internal" href="#putting-it-all-together">Putting it All Together</a></li>
<li><a class="reference internal" href="#running-the-code">Running the Code</a></li>
<li><a class="reference internal" href="#tips-and-tricks">Tips and Tricks</a><ul>
<li><a class="reference internal" href="#choosing-hyperparameters">Choosing Hyperparameters</a><ul>
<li><a class="reference internal" href="#number-of-filters">Number of filters</a></li>
<li><a class="reference internal" href="#filter-shape">Filter Shape</a></li>
<li><a class="reference internal" href="#max-pooling-shape">Max Pooling Shape</a></li>
<li><a class="reference internal" href="#tips">Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="http://deeplearning.net/tutorial/mlp.html" title="previous chapter">Multilayer Perceptron</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="http://deeplearning.net/tutorial/dA.html" title="next chapter">Denoising Autoencoders (dA)</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="http://deeplearning.net/tutorial/_sources/lenet.txt" rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input name="q" type="text"></div>
      <div><input value="Go" type="submit"></div>
      <input name="check_keywords" value="yes" type="hidden">
      <input name="area" value="default" type="hidden">
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="convolutional-neural-networks-lenet">
<span id="lenet"></span><h1>Convolutional Neural Networks (LeNet)<a class="headerlink" href="#convolutional-neural-networks-lenet" title="Permalink to this headline">¶</a></h1>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>This section assumes the reader has already read through <a class="reference internal" href="http://deeplearning.net/tutorial/logreg.html"><span class="doc">Classifying MNIST digits using Logistic Regression</span></a> and
<a class="reference internal" href="http://deeplearning.net/tutorial/mlp.html"><span class="doc">Multilayer Perceptron</span></a>. Additionally, it uses the following new Theano functions and concepts:
<a class="reference external" href="http://deeplearning.net/software/theano/tutorial/examples.html?highlight=tanh">T.tanh</a>, <a class="reference external" href="http://deeplearning.net/software/theano/tutorial/examples.html#using-shared-variables">shared variables</a>, <a class="reference external" href="http://deeplearning.net/software/theano/tutorial/adding.html#adding-two-scalars">basic arithmetic ops</a>, <a class="reference external" href="http://deeplearning.net/software/theano/tutorial/examples.html#computing-gradients">T.grad</a>,
<a class="reference external" href="http://deeplearning.net/software/theano/library/config.html#config.floatX">floatX</a>, <a class="reference external" href="http://deeplearning.net/software/theano/library/tensor/signal/pool.html">pool</a> , <a class="reference external" href="http://deeplearning.net/software/theano/library/tensor/signal/conv.html#module-conv">conv2d</a>, <a class="reference external" href="http://deeplearning.net/software/theano/library/tensor/basic.html#tensor._tensor_py_operators.dimshuffle">dimshuffle</a>. If you intend to run the
code on GPU also read <a class="reference external" href="http://deeplearning.net/software/theano/tutorial/using_gpu.html">GPU</a>.</p>
<p>To run this example on a GPU, you need a good GPU. It needs
at least 1GB of GPU RAM.  More may be required if your monitor is
connected to the GPU.</p>
<p class="last">When the GPU is connected to the monitor, there is a limit
of a few seconds for each GPU function call. This is needed as
current GPUs can’t be used for the monitor while doing
computation. Without this limit, the screen would freeze
for too long and make it look as if the computer froze.
This example hits this limit with medium-quality GPUs. When the
GPU isn’t connected to a monitor, there is no time limit. You can
lower the batch size to fix the time out problem.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The code for this section is available for download <a class="reference external" href="http://deeplearning.net/tutorial/code/convolutional_mlp.py">here</a> and the <a class="reference external" href="https://raw.githubusercontent.com/lisa-lab/DeepLearningTutorials/master/doc/images/3wolfmoon.jpg">3wolfmoon image</a></p>
</div>
<div class="section" id="motivation">
<h2>Motivation<a class="headerlink" href="#motivation" title="Permalink to this headline">¶</a></h2>
<p>Convolutional Neural Networks (CNN) are biologically-inspired variants of MLPs.
From Hubel and Wiesel’s early work on the cat’s visual cortex <a class="reference internal" href="http://deeplearning.net/tutorial/references.html#hubel68" id="id1">[Hubel68]</a>, we
know the visual cortex contains a complex arrangement of cells. These cells are
sensitive to small sub-regions of the visual field, called a <em>receptive
field</em>. The sub-regions are tiled to cover the entire visual field. These
cells act as local filters over the input space and are well-suited to exploit
the strong spatially local correlation present in natural images.</p>
<p>Additionally, two basic cell types have been identified: Simple cells respond
maximally to specific edge-like patterns within their receptive field. Complex
cells have larger receptive fields and are locally invariant to the exact
position of the pattern.</p>
<p>The animal visual cortex being the most powerful visual processing system in
existence, it seems natural to emulate its behavior. Hence, many
neurally-inspired models can be found in the literature. To name a few: the
NeoCognitron <a class="reference internal" href="http://deeplearning.net/tutorial/references.html#fukushima" id="id2">[Fukushima]</a>, HMAX <a class="reference internal" href="http://deeplearning.net/tutorial/references.html#serre07" id="id3">[Serre07]</a> and LeNet-5 <a class="reference internal" href="http://deeplearning.net/tutorial/references.html#lecun98" id="id4">[LeCun98]</a>, which will
be the focus of this tutorial.</p>
</div>
<div class="section" id="sparse-connectivity">
<h2>Sparse Connectivity<a class="headerlink" href="#sparse-connectivity" title="Permalink to this headline">¶</a></h2>
<p>CNNs exploit spatially-local correlation by enforcing a local connectivity
pattern between neurons of adjacent layers. In other words, the inputs of
hidden units in layer <strong>m</strong> are from a subset of units in layer <strong>m-1</strong>, units
that have spatially contiguous receptive fields. We can illustrate this
graphically as follows:</p>
<div class="figure align-center">
<img alt="_images/sparse_1D_nn.png" src="tutorial_files/sparse_1D_nn.png">
</div>
<p>Imagine that layer <strong>m-1</strong> is the input retina. In the above figure, units in
layer <strong>m</strong> have receptive fields of width 3 in the input retina and are thus
only connected to 3 adjacent neurons in the retina layer. Units in layer
<strong>m+1</strong> have a similar connectivity with the layer below. We say that their
receptive field with respect to the layer below is also 3, but their receptive
field with respect to the input is larger (5). Each unit is unresponsive to
variations outside of its receptive field with respect to the retina. The
architecture thus ensures that the learnt “filters” produce the strongest
response to a spatially local input pattern.</p>
<p>However, as shown above, stacking many such layers leads to (non-linear)
“filters” that become increasingly “global” (i.e. responsive to a larger region
of pixel space). For example, the unit in hidden layer <strong>m+1</strong> can encode a
non-linear feature of width 5 (in terms of pixel space).</p>
</div>
<div class="section" id="shared-weights">
<h2>Shared Weights<a class="headerlink" href="#shared-weights" title="Permalink to this headline">¶</a></h2>
<p>In addition, in CNNs, each filter <img class="math" src="tutorial_files/42a24757111b1fd5409141d3c2d481a92d746694.png" alt="h_i"> is replicated across the entire
visual field. These replicated units share the same parameterization (weight
vector and bias) and form a <em>feature map</em>.</p>
<div class="figure align-center">
<img alt="_images/conv_1D_nn.png" src="tutorial_files/conv_1D_nn.png">
</div>
<p>In the above figure, we show 3 hidden units belonging to the same feature map.
Weights of the same color are shared—constrained to be identical. Gradient
descent can still be used to learn such shared parameters, with only a small
change to the original algorithm. The gradient of a shared weight is simply the
sum of the gradients of the parameters being shared.</p>
<p>Replicating units in this way allows for features to be detected <em>regardless
of their position in the visual field.</em> Additionally, weight sharing increases
learning efficiency by greatly reducing the number of free parameters being
learnt. The constraints on the model enable CNNs to achieve better
generalization on vision problems.</p>
</div>
<div class="section" id="details-and-notation">
<h2>Details and Notation<a class="headerlink" href="#details-and-notation" title="Permalink to this headline">¶</a></h2>
<p>A feature map is obtained by repeated application of a function across
sub-regions of the entire image, in other words, by <em>convolution</em> of the
input image with a linear filter, adding a bias term and then applying a
non-linear function. If we denote the k-th feature map at a given layer as
<img class="math" src="tutorial_files/fbe196988ca90a537a8e45cf8b8fb6b31287d37e.png" alt="h^k">, whose filters are determined by the weights <img class="math" src="tutorial_files/dd6ab405f99e5092093624e9a687ede298bae2a7.png" alt="W^k"> and bias
<img class="math" src="tutorial_files/d93ab0d06dc86bce399c5878eff51890f812d1ac.png" alt="b_k">, then the feature map <img class="math" src="tutorial_files/fbe196988ca90a537a8e45cf8b8fb6b31287d37e.png" alt="h^k"> is obtained as follows (for
<img class="math" src="tutorial_files/60102a46429b2839312e116a43551fd94f3c3160.png" alt="tanh"> non-linearities):</p>
<div class="math">
<p><img src="tutorial_files/5f4d1d3beb4d9d0a25579bdd591fd58e5a20bcf8.png" alt="h^k_{ij} = \tanh ( (W^k * x)_{ij} + b_k )."></p>
</div><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Recall the following definition of convolution for a 1D signal.
<img class="math" src="tutorial_files/ebecd534421ecfe888609e0d78943c8616e222e5.png" alt="o[n] = f[n]*g[n] = \sum_{u=-\infty}^{\infty} f[u] g[n-u] = \sum_{u=-\infty}^{\infty} f[n-u] g[u]">.</p>
<p class="last">This can be extended to 2D as follows:
<img class="math" src="tutorial_files/018bdc7d2f74411a1895e3075ffb0c6cbe4c7521.png" alt="o[m,n] = f[m,n]*g[m,n] = \sum_{u=-\infty}^{\infty} \sum_{v=-\infty}^{\infty} f[u,v] g[m-u,n-v]">.</p>
</div>
<p>To form a richer representation of the data, each hidden layer is composed of
<em>multiple</em> feature maps, <img class="math" src="tutorial_files/dc13e3380640f2d875a8f4bdd3307ab72f989d26.png" alt="\{h^{(k)}, k=0..K\}">. The weights <img class="math" src="tutorial_files/597c3a32b95a572264f23d8ac380dea3e50e0cc0.png" alt="W"> of
a hidden layer can be represented in a 4D tensor containing elements for every
combination of destination feature map, source feature map, source vertical
position, and source horizontal position. The biases <img class="math" src="tutorial_files/30f56f8625112194b5cbc79b78f8213604a50dd2.png" alt="b"> can be
represented as a vector containing one element for every destination feature
map. We illustrate this graphically as follows:</p>
<div class="figure align-center" id="id5">
<img alt="_images/cnn_explained.png" src="tutorial_files/cnn_explained.png">
<p class="caption"><span class="caption-text"><strong>Figure 1</strong>: example of a convolutional layer</span></p>
</div>
<p>The figure shows two layers of a CNN. <strong>Layer m-1</strong> contains four feature maps.
<strong>Hidden layer m</strong> contains two feature maps (<img class="math" src="tutorial_files/a22883b968c1a6b1d8ca85024de2248816979c21.png" alt="h^0"> and <img class="math" src="tutorial_files/116528ca9a360acf2592b38c6156659996c17516.png" alt="h^1">).
Pixels (neuron outputs) in <img class="math" src="tutorial_files/a22883b968c1a6b1d8ca85024de2248816979c21.png" alt="h^0"> and <img class="math" src="tutorial_files/116528ca9a360acf2592b38c6156659996c17516.png" alt="h^1"> (outlined as blue and
red squares) are computed from pixels of layer (m-1) which fall within their
2x2 receptive field in the layer below (shown as colored rectangles). Notice
how the receptive field spans all four input feature maps. The weights
<img class="math" src="tutorial_files/7c2b5d3aeb392b39608933b6ab1ac67a86ca9e5d.png" alt="W^0"> and <img class="math" src="tutorial_files/71b3e64fed7a01ac52f04ed764b93ebfd98d7ea6.png" alt="W^1"> of <img class="math" src="tutorial_files/a22883b968c1a6b1d8ca85024de2248816979c21.png" alt="h^0"> and <img class="math" src="tutorial_files/116528ca9a360acf2592b38c6156659996c17516.png" alt="h^1"> are thus 3D weight
tensors. The leading dimension indexes the input feature maps, while the other
two refer to the pixel coordinates.</p>
<p>Putting it all together, <img class="math" src="tutorial_files/e992a11ef438acbd7a549b2a4da31c4c54da6398.png" alt="W^{kl}_{ij}"> denotes the weight connecting
each pixel of the k-th feature map at layer m, with the pixel at coordinates
(i,j) of the l-th feature map of layer (m-1).</p>
</div>
<div class="section" id="the-convolution-operator">
<h2>The Convolution Operator<a class="headerlink" href="#the-convolution-operator" title="Permalink to this headline">¶</a></h2>
<p>ConvOp is the main workhorse for implementing a convolutional layer in Theano.
ConvOp is used by <code class="docutils literal"><span class="pre">theano.tensor.signal.conv2d</span></code>, which takes two symbolic inputs:</p>
<ul class="simple">
<li>a 4D tensor corresponding to a mini-batch of input images. The shape of the
tensor is as follows: [mini-batch size, number of input feature maps, image
height, image width].</li>
<li>a 4D tensor corresponding to the weight matrix <img class="math" src="tutorial_files/597c3a32b95a572264f23d8ac380dea3e50e0cc0.png" alt="W">. The shape of the
tensor is: [number of feature maps at layer m, number of feature maps at
layer m-1, filter height, filter width]</li>
</ul>
<p>Below is the Theano code for implementing a convolutional layer similar to the
one of Figure 1. The input consists of 3 features maps (an RGB color image) of size
120x160. We use two convolutional filters with 9x9 receptive fields.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">theano</span>
<span class="kn">from</span> <span class="nn">theano</span> <span class="kn">import</span> <span class="n">tensor</span> <span class="k">as</span> <span class="n">T</span>
<span class="kn">from</span> <span class="nn">theano.tensor.nnet</span> <span class="kn">import</span> <span class="n">conv2d</span>

<span class="kn">import</span> <span class="nn">numpy</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">23455</span><span class="p">)</span>

<span class="c1"># instantiate 4D tensor for input</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">tensor4</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'input'</span><span class="p">)</span>

<span class="c1"># initialize shared variable for weights.</span>
<span class="n">w_shp</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="n">w_bound</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="mi">9</span> <span class="o">*</span> <span class="mi">9</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span> <span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
            <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
                <span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">w_bound</span><span class="p">,</span>
                <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">w_bound</span><span class="p">,</span>
                <span class="n">size</span><span class="o">=</span><span class="n">w_shp</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">input</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">name</span> <span class="o">=</span><span class="s1">'W'</span><span class="p">)</span>

<span class="c1"># initialize shared variable for bias (1D tensor) with random values</span>
<span class="c1"># IMPORTANT: biases are usually initialized to zero. However in this</span>
<span class="c1"># particular application, we simply apply the convolutional layer to</span>
<span class="c1"># an image without learning the parameters. We therefore initialize</span>
<span class="c1"># them to random values to "simulate" learning.</span>
<span class="n">b_shp</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
            <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=-.</span><span class="mi">5</span><span class="p">,</span> <span class="n">high</span><span class="o">=.</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">b_shp</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">input</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">name</span> <span class="o">=</span><span class="s1">'b'</span><span class="p">)</span>

<span class="c1"># build symbolic expression that computes the convolution of input with filters in w</span>
<span class="n">conv_out</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>

<span class="c1"># build symbolic expression to add bias and apply activation function, i.e. produce neural net layer output</span>
<span class="c1"># A few words on ``dimshuffle`` :</span>
<span class="c1">#   ``dimshuffle`` is a powerful tool in reshaping a tensor;</span>
<span class="c1">#   what it allows you to do is to shuffle dimension around</span>
<span class="c1">#   but also to insert new ones along which the tensor will be</span>
<span class="c1">#   broadcastable;</span>
<span class="c1">#   dimshuffle('x', 2, 'x', 0, 1)</span>
<span class="c1">#   This will work on 3d tensors with no broadcastable</span>
<span class="c1">#   dimensions. The first dimension will be broadcastable,</span>
<span class="c1">#   then we will have the third dimension of the input tensor as</span>
<span class="c1">#   the second of the resulting tensor, etc. If the tensor has</span>
<span class="c1">#   shape (20, 30, 40), the resulting tensor will have dimensions</span>
<span class="c1">#   (1, 40, 1, 20, 30). (AxBxC tensor is mapped to 1xCx1xAxB tensor)</span>
<span class="c1">#   More examples:</span>
<span class="c1">#    dimshuffle('x') -&gt; make a 0d (scalar) into a 1d vector</span>
<span class="c1">#    dimshuffle(0, 1) -&gt; identity</span>
<span class="c1">#    dimshuffle(1, 0) -&gt; inverts the first and second dimensions</span>
<span class="c1">#    dimshuffle('x', 0) -&gt; make a row out of a 1d vector (N to 1xN)</span>
<span class="c1">#    dimshuffle(0, 'x') -&gt; make a column out of a 1d vector (N to Nx1)</span>
<span class="c1">#    dimshuffle(2, 0, 1) -&gt; AxBxC to CxAxB</span>
<span class="c1">#    dimshuffle(0, 'x', 1) -&gt; AxB to Ax1xB</span>
<span class="c1">#    dimshuffle(1, 'x', 0) -&gt; AxB to Bx1xA</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">conv_out</span> <span class="o">+</span> <span class="n">b</span><span class="o">.</span><span class="n">dimshuffle</span><span class="p">(</span><span class="s1">'x'</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">'x'</span><span class="p">,</span> <span class="s1">'x'</span><span class="p">))</span>

<span class="c1"># create theano function to compute filtered images</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">function</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s have a little bit of fun with this...</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pylab</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="c1"># open random image of dimensions 639x516</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">'doc/images/3wolfmoon.jpg'</span><span class="p">))</span>
<span class="c1"># dimensions are (height, width, channel)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">'float64'</span><span class="p">)</span> <span class="o">/</span> <span class="mf">256.</span>

<span class="c1"># put image in 4D tensor of shape (1, 3, height, width)</span>
<span class="n">img_</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">639</span><span class="p">,</span> <span class="mi">516</span><span class="p">)</span>
<span class="n">filtered_img</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">img_</span><span class="p">)</span>

<span class="c1"># plot original image and first and second components of output</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span> <span class="n">pylab</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">);</span> <span class="n">pylab</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">gray</span><span class="p">();</span>
<span class="c1"># recall that the convOp output (filtered image) is actually a "minibatch",</span>
<span class="c1"># of size 1 here, so we take index 0 in the first dimension:</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">);</span> <span class="n">pylab</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">);</span> <span class="n">pylab</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">filtered_img</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">);</span> <span class="n">pylab</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">);</span> <span class="n">pylab</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">filtered_img</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>This should generate the following output.</p>
<img alt="_images/3wolfmoon_output.png" class="align-center" src="tutorial_files/3wolfmoon_output.png">
<p>Notice that a randomly initialized filter acts very much like an edge detector!</p>
<p>Note that we use the same weight initialization formula as with the MLP.
Weights are sampled randomly from a uniform distribution in the range
[-1/fan-in, 1/fan-in], where fan-in is the number of inputs to a hidden unit.
For MLPs, this was the number of units in the layer below. For CNNs however, we
have to take into account the number of input feature maps and the size of the
receptive fields.</p>
</div>
<div class="section" id="maxpooling">
<h2>MaxPooling<a class="headerlink" href="#maxpooling" title="Permalink to this headline">¶</a></h2>
<p>Another important concept of CNNs is <em>max-pooling,</em> which is a form of
non-linear down-sampling. Max-pooling partitions the input image into
a set of non-overlapping rectangles and, for each such sub-region, outputs the
maximum value.</p>
<dl class="docutils">
<dt>Max-pooling is useful in vision for two reasons:</dt>
<dd><ol class="first last arabic">
<li><p class="first">By eliminating non-maximal values, it reduces computation for upper layers.</p>
</li>
<li><p class="first">It provides a form of translation invariance. Imagine
cascading a max-pooling layer with a convolutional layer. There are 8
directions in which one can translate the input image by a single pixel.
If max-pooling is done over a 2x2 region, 3 out of these 8 possible
configurations will produce exactly the same output at the convolutional
layer. For max-pooling over a 3x3 window, this jumps to 5/8.</p>
<p>Since it provides additional robustness to position, max-pooling is a
“smart” way of reducing the dimensionality of intermediate representations.</p>
</li>
</ol>
</dd>
</dl>
<p>Max-pooling is done in Theano by way of
<code class="docutils literal"><span class="pre">theano.tensor.signal.pool.pool_2d</span></code>. This function takes as input
an N dimensional tensor (where N &gt;= 2) and a downscaling factor and performs
max-pooling over the 2 trailing dimensions of the tensor.</p>
<p>An example is worth a thousand words:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">theano.tensor.signal</span> <span class="kn">import</span> <span class="n">pool</span>

<span class="nb">input</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">dtensor4</span><span class="p">(</span><span class="s1">'input'</span><span class="p">)</span>
<span class="n">maxpool_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">pool_out</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">pool_2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">maxpool_shape</span><span class="p">,</span> <span class="n">ignore_border</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">function</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span><span class="n">pool_out</span><span class="p">)</span>

<span class="n">invals</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="k">print</span> <span class="s1">'With ignore_border set to True:'</span>
<span class="k">print</span> <span class="s1">'invals[0, 0, :, :] =</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="n">invals</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
<span class="k">print</span> <span class="s1">'output[0, 0, :, :] =</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">invals</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>

<span class="n">pool_out</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">pool_2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">maxpool_shape</span><span class="p">,</span> <span class="n">ignore_border</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">function</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span><span class="n">pool_out</span><span class="p">)</span>
<span class="k">print</span> <span class="s1">'With ignore_border set to False:'</span>
<span class="k">print</span> <span class="s1">'invals[1, 0, :, :] =</span><span class="se">\n</span><span class="s1"> '</span><span class="p">,</span> <span class="n">invals</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
<span class="k">print</span> <span class="s1">'output[1, 0, :, :] =</span><span class="se">\n</span><span class="s1"> '</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">invals</span><span class="p">)[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
</pre></div>
</div>
<p>This should generate the following output:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>With ignore_border <span class="nb">set</span> to True:
    invals<span class="o">[</span>0, 0, :, :<span class="o">]</span> <span class="o">=</span>
    <span class="o">[[</span>  4.17022005e-01   7.20324493e-01   1.14374817e-04   3.02332573e-01 1.46755891e-01<span class="o">]</span>
     <span class="o">[</span>  9.23385948e-02   1.86260211e-01   3.45560727e-01   3.96767474e-01 5.38816734e-01<span class="o">]</span>
     <span class="o">[</span>  4.19194514e-01   6.85219500e-01   2.04452250e-01   8.78117436e-01 2.73875932e-02<span class="o">]</span>
     <span class="o">[</span>  6.70467510e-01   4.17304802e-01   5.58689828e-01   1.40386939e-01 1.98101489e-01<span class="o">]</span>
     <span class="o">[</span>  8.00744569e-01   9.68261576e-01   3.13424178e-01   6.92322616e-01 8.76389152e-01<span class="o">]]</span>
    output<span class="o">[</span>0, 0, :, :<span class="o">]</span> <span class="o">=</span>
    <span class="o">[[</span> 0.72032449  0.39676747<span class="o">]</span>
     <span class="o">[</span> 0.6852195   0.87811744<span class="o">]]</span>

With ignore_border <span class="nb">set</span> to False:
    invals<span class="o">[</span>1, 0, :, :<span class="o">]</span> <span class="o">=</span>
    <span class="o">[[</span> 0.01936696  0.67883553  0.21162812  0.26554666  0.49157316<span class="o">]</span>
     <span class="o">[</span> 0.05336255  0.57411761  0.14672857  0.58930554  0.69975836<span class="o">]</span>
     <span class="o">[</span> 0.10233443  0.41405599  0.69440016  0.41417927  0.04995346<span class="o">]</span>
     <span class="o">[</span> 0.53589641  0.66379465  0.51488911  0.94459476  0.58655504<span class="o">]</span>
     <span class="o">[</span> 0.90340192  0.1374747   0.13927635  0.80739129  0.39767684<span class="o">]]</span>
    output<span class="o">[</span>1, 0, :, :<span class="o">]</span> <span class="o">=</span>
    <span class="o">[[</span> 0.67883553  0.58930554  0.69975836<span class="o">]</span>
     <span class="o">[</span> 0.66379465  0.94459476  0.58655504<span class="o">]</span>
     <span class="o">[</span> 0.90340192  0.80739129  0.39767684<span class="o">]]</span>
</pre></div>
</div>
<p>Note that compared to most Theano code, the <code class="docutils literal"><span class="pre">max_pool_2d</span></code> operation is a
little <em>special</em>. It requires the downscaling factor <code class="docutils literal"><span class="pre">ds</span></code> (tuple of length 2
containing downscaling factors for image width and height) to be known at graph
build time. This may change in the near future.</p>
</div>
<div class="section" id="the-full-model-lenet">
<h2>The Full Model: LeNet<a class="headerlink" href="#the-full-model-lenet" title="Permalink to this headline">¶</a></h2>
<p>Sparse, convolutional layers and max-pooling are at the heart of the LeNet
family of models. While the exact details of the model will vary greatly,
the figure below shows a graphical depiction of a LeNet model.</p>
<img alt="_images/mylenet.png" class="align-center" src="tutorial_files/mylenet.png">
<p>The lower-layers are composed to alternating convolution and max-pooling
layers. The upper-layers however are fully-connected and correspond to a
traditional MLP (hidden layer + logistic regression). The input to the
first fully-connected layer is the set of all features maps at the layer
below.</p>
<p>From an implementation point of view, this means lower-layers operate on 4D
tensors. These are then flattened to a 2D matrix of rasterized feature maps,
to be compatible with our previous MLP implementation.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Note that the term “convolution” could corresponds to different mathematical operations:</p>
<ol class="arabic simple">
<li><a class="reference external" href="http://deeplearning.net/software/theano/library/tensor/nnet/conv.html#theano.tensor.nnet.conv2d">theano.tensor.nnet.conv2d</a>,
which is the most common one in almost all of the recent published
convolutional models.
In this operation, each output feature map is connected to each
input feature map by a different 2D filter, and its value is the sum of
the individual convolution of all inputs through the corresponding filter.</li>
<li>The convolution used in the original LeNet model: In this work,
each output feature map is only connected to a subset of input
feature maps.</li>
<li>The convolution used in signal processing:
<a class="reference external" href="http://deeplearning.net/software/theano/library/tensor/signal/conv.html#theano.tensor.signal.conv.conv2d">theano.tensor.signal.conv.conv2d</a>,
which works only on single channel inputs.</li>
</ol>
<p class="last">Here, we use the first operation, so this models differ slightly
from the original LeNet paper. One reason to use 2. would be to
reduce the amount of computation needed, but modern hardware makes
it as fast to have the full connection pattern. Another reason would
be to slightly reduce the number of free parameters, but we have
other regularization techniques at our disposal.</p>
</div>
</div>
<div class="section" id="putting-it-all-together">
<h2>Putting it All Together<a class="headerlink" href="#putting-it-all-together" title="Permalink to this headline">¶</a></h2>
<p>We now have all we need to implement a LeNet model in Theano. We start with the
LeNetConvPoolLayer class, which implements a {convolution + max-pooling}
layer.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LeNetConvPoolLayer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">"""Pool Layer of a convolutional network """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">filter_shape</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">poolsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)):</span>
        <span class="sd">"""</span>
<span class="sd">        Allocate a LeNetConvPoolLayer with shared variable internal parameters.</span>

<span class="sd">        :type rng: numpy.random.RandomState</span>
<span class="sd">        :param rng: a random number generator used to initialize weights</span>

<span class="sd">        :type input: theano.tensor.dtensor4</span>
<span class="sd">        :param input: symbolic image tensor, of shape image_shape</span>

<span class="sd">        :type filter_shape: tuple or list of length 4</span>
<span class="sd">        :param filter_shape: (number of filters, num input feature maps,</span>
<span class="sd">                              filter height, filter width)</span>

<span class="sd">        :type image_shape: tuple or list of length 4</span>
<span class="sd">        :param image_shape: (batch size, num input feature maps,</span>
<span class="sd">                             image height, image width)</span>

<span class="sd">        :type poolsize: tuple or list of length 2</span>
<span class="sd">        :param poolsize: the downsampling (pooling) factor (#rows, #cols)</span>
<span class="sd">        """</span>

        <span class="k">assert</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">filter_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="nb">input</span>

        <span class="c1"># there are "num input feature maps * filter height * filter width"</span>
        <span class="c1"># inputs to each hidden unit</span>
        <span class="n">fan_in</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="c1"># each unit in the lower layer receives a gradient from:</span>
        <span class="c1"># "num output feature maps * filter height * filter width" /</span>
        <span class="c1">#   pooling size</span>
        <span class="n">fan_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span> <span class="o">//</span>
                   <span class="n">numpy</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">poolsize</span><span class="p">))</span>
        <span class="c1"># initialize weights with random weights</span>
        <span class="n">W_bound</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">6.</span> <span class="o">/</span> <span class="p">(</span><span class="n">fan_in</span> <span class="o">+</span> <span class="n">fan_out</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span>
            <span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
                <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="n">W_bound</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">W_bound</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">filter_shape</span><span class="p">),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">theano</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">floatX</span>
            <span class="p">),</span>
            <span class="n">borrow</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="c1"># the bias is a 1D tensor -- one bias per output feature map</span>
        <span class="n">b_values</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">theano</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">floatX</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">b_values</span><span class="p">,</span> <span class="n">borrow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># convolve input feature maps with filters</span>
        <span class="n">conv_out</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span>
            <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span>
            <span class="n">filters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">,</span>
            <span class="n">filter_shape</span><span class="o">=</span><span class="n">filter_shape</span><span class="p">,</span>
            <span class="n">input_shape</span><span class="o">=</span><span class="n">image_shape</span>
        <span class="p">)</span>

        <span class="c1"># pool each feature map individually, using maxpooling</span>
        <span class="n">pooled_out</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">pool_2d</span><span class="p">(</span>
            <span class="nb">input</span><span class="o">=</span><span class="n">conv_out</span><span class="p">,</span>
            <span class="n">ds</span><span class="o">=</span><span class="n">poolsize</span><span class="p">,</span>
            <span class="n">ignore_border</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="c1"># add the bias term. Since the bias is a vector (1D array), we first</span>
        <span class="c1"># reshape it to a tensor of shape (1, n_filters, 1, 1). Each bias will</span>
        <span class="c1"># thus be broadcasted across mini-batches and feature map</span>
        <span class="c1"># width &amp; height</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">pooled_out</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">dimshuffle</span><span class="p">(</span><span class="s1">'x'</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">'x'</span><span class="p">,</span> <span class="s1">'x'</span><span class="p">))</span>

        <span class="c1"># store parameters of this layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">]</span>

        <span class="c1"># keep track of model input</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="nb">input</span>
</pre></div>
</div>
<p>Notice that when initializing the weight values, the fan-in is determined by
the size of the receptive fields and the number of input feature maps.</p>
<p>Finally, using the LogisticRegression class defined in <a class="reference internal" href="http://deeplearning.net/tutorial/logreg.html"><span class="doc">Classifying MNIST digits using Logistic Regression</span></a> and
the HiddenLayer class defined in <a class="reference internal" href="http://deeplearning.net/tutorial/mlp.html"><span class="doc">Multilayer Perceptron</span></a> , we can
instantiate the network as follows.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>    <span class="n">x</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="s1">'x'</span><span class="p">)</span>   <span class="c1"># the data is presented as rasterized images</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">ivector</span><span class="p">(</span><span class="s1">'y'</span><span class="p">)</span>  <span class="c1"># the labels are presented as 1D vector of</span>
                        <span class="c1"># [int] labels</span>

    <span class="c1">######################</span>
    <span class="c1"># BUILD ACTUAL MODEL #</span>
    <span class="c1">######################</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'... building the model'</span><span class="p">)</span>

    <span class="c1"># Reshape matrix of rasterized images of shape (batch_size, 28 * 28)</span>
    <span class="c1"># to a 4D tensor, compatible with our LeNetConvPoolLayer</span>
    <span class="c1"># (28, 28) is the size of MNIST images.</span>
    <span class="n">layer0_input</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>

    <span class="c1"># Construct the first convolutional pooling layer:</span>
    <span class="c1"># filtering reduces the image size to (28-5+1 , 28-5+1) = (24, 24)</span>
    <span class="c1"># maxpooling reduces this further to (24/2, 24/2) = (12, 12)</span>
    <span class="c1"># 4D output tensor is thus of shape (batch_size, nkerns[0], 12, 12)</span>
    <span class="n">layer0</span> <span class="o">=</span> <span class="n">LeNetConvPoolLayer</span><span class="p">(</span>
        <span class="n">rng</span><span class="p">,</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">layer0_input</span><span class="p">,</span>
        <span class="n">image_shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span>
        <span class="n">filter_shape</span><span class="o">=</span><span class="p">(</span><span class="n">nkerns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
        <span class="n">poolsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Construct the second convolutional pooling layer</span>
    <span class="c1"># filtering reduces the image size to (12-5+1, 12-5+1) = (8, 8)</span>
    <span class="c1"># maxpooling reduces this further to (8/2, 8/2) = (4, 4)</span>
    <span class="c1"># 4D output tensor is thus of shape (batch_size, nkerns[1], 4, 4)</span>
    <span class="n">layer1</span> <span class="o">=</span> <span class="n">LeNetConvPoolLayer</span><span class="p">(</span>
        <span class="n">rng</span><span class="p">,</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">layer0</span><span class="o">.</span><span class="n">output</span><span class="p">,</span>
        <span class="n">image_shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">nkerns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span>
        <span class="n">filter_shape</span><span class="o">=</span><span class="p">(</span><span class="n">nkerns</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nkerns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
        <span class="n">poolsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># the HiddenLayer being fully-connected, it operates on 2D matrices of</span>
    <span class="c1"># shape (batch_size, num_pixels) (i.e matrix of rasterized images).</span>
    <span class="c1"># This will generate a matrix of shape (batch_size, nkerns[1] * 4 * 4),</span>
    <span class="c1"># or (500, 50 * 4 * 4) = (500, 800) with the default values.</span>
    <span class="n">layer2_input</span> <span class="o">=</span> <span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># construct a fully-connected sigmoidal layer</span>
    <span class="n">layer2</span> <span class="o">=</span> <span class="n">HiddenLayer</span><span class="p">(</span>
        <span class="n">rng</span><span class="p">,</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">layer2_input</span><span class="p">,</span>
        <span class="n">n_in</span><span class="o">=</span><span class="n">nkerns</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">n_out</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">T</span><span class="o">.</span><span class="n">tanh</span>
    <span class="p">)</span>

    <span class="c1"># classify the values of the fully-connected sigmoidal layer</span>
    <span class="n">layer3</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">layer2</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">n_in</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">n_out</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="c1"># the cost we minimize during training is the NLL of the model</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">layer3</span><span class="o">.</span><span class="n">negative_log_likelihood</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="c1"># create a function to compute the mistakes that are made by the model</span>
    <span class="n">test_model</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
        <span class="p">[</span><span class="n">index</span><span class="p">],</span>
        <span class="n">layer3</span><span class="o">.</span><span class="n">errors</span><span class="p">(</span><span class="n">y</span><span class="p">),</span>
        <span class="n">givens</span><span class="o">=</span><span class="p">{</span>
            <span class="n">x</span><span class="p">:</span> <span class="n">test_set_x</span><span class="p">[</span><span class="n">index</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">],</span>
            <span class="n">y</span><span class="p">:</span> <span class="n">test_set_y</span><span class="p">[</span><span class="n">index</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">)</span>

    <span class="n">validate_model</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
        <span class="p">[</span><span class="n">index</span><span class="p">],</span>
        <span class="n">layer3</span><span class="o">.</span><span class="n">errors</span><span class="p">(</span><span class="n">y</span><span class="p">),</span>
        <span class="n">givens</span><span class="o">=</span><span class="p">{</span>
            <span class="n">x</span><span class="p">:</span> <span class="n">valid_set_x</span><span class="p">[</span><span class="n">index</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">],</span>
            <span class="n">y</span><span class="p">:</span> <span class="n">valid_set_y</span><span class="p">[</span><span class="n">index</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">)</span>

    <span class="c1"># create a list of all model parameters to be fit by gradient descent</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">layer3</span><span class="o">.</span><span class="n">params</span> <span class="o">+</span> <span class="n">layer2</span><span class="o">.</span><span class="n">params</span> <span class="o">+</span> <span class="n">layer1</span><span class="o">.</span><span class="n">params</span> <span class="o">+</span> <span class="n">layer0</span><span class="o">.</span><span class="n">params</span>

    <span class="c1"># create a list of gradients for all model parameters</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

    <span class="c1"># train_model is a function that updates the model parameters by</span>
    <span class="c1"># SGD Since this model has many parameters, it would be tedious to</span>
    <span class="c1"># manually create an update rule for each model parameter. We thus</span>
    <span class="c1"># create the updates list by automatically looping over all</span>
    <span class="c1"># (params[i], grads[i]) pairs.</span>
    <span class="n">updates</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="n">param_i</span><span class="p">,</span> <span class="n">param_i</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_i</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">param_i</span><span class="p">,</span> <span class="n">grad_i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">train_model</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
        <span class="p">[</span><span class="n">index</span><span class="p">],</span>
        <span class="n">cost</span><span class="p">,</span>
        <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span>
        <span class="n">givens</span><span class="o">=</span><span class="p">{</span>
            <span class="n">x</span><span class="p">:</span> <span class="n">train_set_x</span><span class="p">[</span><span class="n">index</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">],</span>
            <span class="n">y</span><span class="p">:</span> <span class="n">train_set_y</span><span class="p">[</span><span class="n">index</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>We leave out the code that performs the actual training and early-stopping,
since it is exactly the same as with an MLP. The interested reader can
nevertheless access the code in the ‘code’ folder of DeepLearningTutorials.</p>
</div>
<div class="section" id="running-the-code">
<h2>Running the Code<a class="headerlink" href="#running-the-code" title="Permalink to this headline">¶</a></h2>
<p>The user can then run the code by calling:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>python code/convolutional_mlp.py
</pre></div>
</div>
<p>The following output was obtained with the default parameters on a Core i7-2600K
CPU clocked at 3.40GHz and using flags ‘floatX=float32’:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>Optimization complete.
Best validation score of 0.910000 % obtained at iteration 17800,with <span class="nb">test</span>
performance 0.920000 %
The code <span class="k">for</span> file convolutional_mlp.py ran <span class="k">for</span> 380.28m
</pre></div>
</div>
<p>Using a GeForce GTX 285, we obtained the following:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>Optimization complete.
Best validation score of 0.910000 % obtained at iteration 15500,with <span class="nb">test</span>
performance 0.930000 %
The code <span class="k">for</span> file convolutional_mlp.py ran <span class="k">for</span> 46.76m
</pre></div>
</div>
<p>And similarly on a GeForce GTX 480:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>Optimization complete.
Best validation score of 0.910000 % obtained at iteration 16400,with <span class="nb">test</span>
performance 0.930000 %
The code <span class="k">for</span> file convolutional_mlp.py ran <span class="k">for</span> 32.52m
</pre></div>
</div>
<p>Note that the discrepancies in validation and test error (as well as iteration
count) are due to different implementations of the rounding mechanism in
hardware. They can be safely ignored.</p>
</div>
<div class="section" id="tips-and-tricks">
<h2>Tips and Tricks<a class="headerlink" href="#tips-and-tricks" title="Permalink to this headline">¶</a></h2>
<div class="section" id="choosing-hyperparameters">
<h3>Choosing Hyperparameters<a class="headerlink" href="#choosing-hyperparameters" title="Permalink to this headline">¶</a></h3>
<p>CNNs are especially tricky to train, as they add even more hyper-parameters than
a standard MLP. While the usual rules of thumb for learning rates and
regularization constants still apply, the following should be kept in mind when
optimizing CNNs.</p>
<div class="section" id="number-of-filters">
<h4>Number of filters<a class="headerlink" href="#number-of-filters" title="Permalink to this headline">¶</a></h4>
<p>When choosing the number of filters per layer, keep in mind that computing the
activations of a single convolutional filter is much more expensive than with
traditional MLPs !</p>
<p>Assume layer <img class="math" src="tutorial_files/3b3737fb3e3fe21d0d389b37fb5ab74f62f0429d.png" alt="(l-1)"> contains <img class="math" src="tutorial_files/b3d52700a4484c188c4a6753dd1e449005a6d49c.png" alt="K^{l-1}"> feature
maps and <img class="math" src="tutorial_files/e01c87c398a0c02d720e52575265fac81d3b4711.png" alt="M \times N"> pixel positions (i.e.,
number of positions times number of feature maps),
and there are <img class="math" src="tutorial_files/b08f62ed5a7f33e0491c440b0c0e5306f8104a46.png" alt="K^l"> filters at layer <img class="math" src="tutorial_files/e65b2be2828e4ac582c36868a52c1caf2f2f2ea9.png" alt="l"> of shape <img class="math" src="tutorial_files/b58f0e0d42521a93f4458796aa372b7261b69f74.png" alt="m \times n">.
Then computing a feature map (applying an <img class="math" src="tutorial_files/b58f0e0d42521a93f4458796aa372b7261b69f74.png" alt="m \times n"> filter
at all <img class="math" src="tutorial_files/0be247154a7f5e8eaa02fe9cf7502541653a3e67.png" alt="(M-m) \times (N-n)"> pixel positions where the
filter can be applied) costs <img class="math" src="tutorial_files/082b22a22e2d3c834c1b20e62e84b115f9146622.png" alt="(M-m) \times (N-n) \times m \times n \times K^{l-1}">.
The total cost is <img class="math" src="tutorial_files/b08f62ed5a7f33e0491c440b0c0e5306f8104a46.png" alt="K^l"> times that. Things may be more complicated if
not all features at one level are connected to all features at the previous one.</p>
<p>For a standard MLP, the cost would only be <img class="math" src="tutorial_files/8d4f2632b8e27105d80afd9c3dfcedd449c0bae7.png" alt="K^l \times K^{l-1}">
where there are <img class="math" src="tutorial_files/b08f62ed5a7f33e0491c440b0c0e5306f8104a46.png" alt="K^l"> different neurons at level <img class="math" src="tutorial_files/e65b2be2828e4ac582c36868a52c1caf2f2f2ea9.png" alt="l">.
As such, the number of filters used in CNNs is typically much
smaller than the number of hidden units in MLPs and depends on the size of the
feature maps (itself a function of input image size and filter shapes).</p>
<p>Since feature map size decreases with depth, layers near the input layer will tend to
have fewer filters while layers higher up can have much more. In fact, to
equalize computation at each layer, the product of the number of features
and the number of pixel positions is typically picked to be roughly constant
across layers. To preserve the information about the input would require
keeping the total number of activations (number of feature maps times
number of pixel positions) to be non-decreasing from one layer to the next
(of course we could hope to get away with less when we are doing supervised
learning). The number of feature maps directly controls capacity and so
that depends on the number of available examples and the complexity of
the task.</p>
</div>
<div class="section" id="filter-shape">
<h4>Filter Shape<a class="headerlink" href="#filter-shape" title="Permalink to this headline">¶</a></h4>
<p>Common filter shapes found in the litterature vary greatly, usually based on
the dataset. Best results on MNIST-sized images (28x28) are usually in the 5x5
range on the first layer, while natural image datasets (often with hundreds of pixels in each
dimension) tend to use larger first-layer filters of shape 12x12 or 15x15.</p>
<p>The trick is thus to find the right level of “granularity” (i.e. filter
shapes) in order to create abstractions at the proper scale, given a
particular dataset.</p>
</div>
<div class="section" id="max-pooling-shape">
<h4>Max Pooling Shape<a class="headerlink" href="#max-pooling-shape" title="Permalink to this headline">¶</a></h4>
<p>Typical values are 2x2 or no max-pooling. Very large input images may warrant
4x4 pooling in the lower-layers. Keep in mind however, that this will reduce the
dimension of the signal by a factor of 16, and may result in throwing away too
much information.</p>
<p class="rubric">Footnotes</p>
<table class="docutils footnote" frame="void" id="f1" rules="none">
<colgroup><col class="label"><col></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td>For clarity, we use the word “unit” or “neuron” to refer to the
artificial neuron and “cell” to refer to the biological neuron.</td></tr>
</tbody>
</table>
</div>
<div class="section" id="tips">
<h4>Tips<a class="headerlink" href="#tips" title="Permalink to this headline">¶</a></h4>
<p>If you want to try this model on a new dataset, here are a few tips that can help you get better results:</p>
<blockquote>
<div><ul class="simple">
<li>Whitening the data (e.g. with PCA)</li>
<li>Decay the learning rate in each epoch</li>
</ul>
</div></blockquote>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="http://deeplearning.net/tutorial/genindex.html" title="General Index">index</a></li>
        <li class="right">
          <a href="http://deeplearning.net/tutorial/dA.html" title="Denoising Autoencoders (dA)">next</a> |</li>
        <li class="right">
          <a href="http://deeplearning.net/tutorial/mlp.html" title="Multilayer Perceptron">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="http://deeplearning.net/tutorial/contents.html">DeepLearning 0.1 documentation</a> »</li> 
      </ul>
    </div>

    <div class="footer" role="contentinfo">
        © Copyright 2008--2010, LISA lab.
      Last updated on Nov 08, 2016.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.4.6.
    </div>
<script type="text/javascript">
  (function() {
    var ga = document.createElement('script');
    ga.src = ('https:' == document.location.protocol ?
              'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    ga.setAttribute('async', 'true');
    document.documentElement.firstChild.appendChild(ga);
  })();
</script>

  
</body></html>